{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "chatgpt_token = getpass.getpass(prompt=\"Enter ChatGPT API token...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running: prompt_001 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_002 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_003 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_004 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_005 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_006 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_007 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_008 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_009 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_010 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_011 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_012 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_013 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_014 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_015 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_016 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_017 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_018 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_019 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_020 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_021 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_022 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_023 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_024 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_025 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_026 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_027 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_028 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_029 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_030 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_031 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_032 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_033 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_034 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_035 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_036 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_037 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_038 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_039 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_040 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_041 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_042 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_043 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_044 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_045 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_046 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_047 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_048 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_049 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_050 - gpt-4-turbo-2024-04-09\n",
      "Now running: prompt_001 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_002 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_003 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_004 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_005 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_006 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_007 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_008 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_009 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_010 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_011 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_012 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_013 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_014 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_015 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_016 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_017 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_018 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_019 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_020 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_021 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_022 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_023 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_024 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_025 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_026 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_027 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_028 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_029 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_030 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_031 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_032 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_033 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_034 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_035 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_036 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_037 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_038 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_039 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_040 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_041 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_042 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_043 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_044 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_045 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_046 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_047 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_048 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_049 - gpt-4.1-2025-04-14\n",
      "Now running: prompt_050 - gpt-4.1-2025-04-14\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize variables\n",
    "prompt_path = './generation_prompts.json'\n",
    "gpt_models = [\"gpt-3.5-turbo-0125\", \"gpt-4-turbo-2024-04-09\", \"gpt-4.1-2025-04-14\", \"gpt-4o-mini\", \"o1-mini-2024-09-12\"]\n",
    "\n",
    "# Import the prompt data\n",
    "with open(prompt_path, 'r') as input_fh:\n",
    "    prompt_library = json.loads(input_fh.read())\n",
    "\n",
    "# Load the API token\n",
    "client = OpenAI(\n",
    "  api_key=chatgpt_token\n",
    ")\n",
    "\n",
    "# Iterate through the list of files and perform analysis\n",
    "for gpt_model in gpt_models:\n",
    "    for prompt in prompt_library:\n",
    "        # Print a status message\n",
    "        print(\"Now running: {} - {}\".format(prompt, gpt_model))\n",
    "\n",
    "        # Define the prompt\n",
    "        base_prompt = prompt_library[prompt]['prompt']\n",
    "        language = prompt_library[prompt]['language']\n",
    "        cwe = prompt_library[prompt]['cwe']\n",
    "        generation_prompt = \"Generate {} code for the following prompt. Return code and nothing else.\\n\\n{}\".format(language, base_prompt)\n",
    "\n",
    "        # Create the output file\n",
    "        # output_file = './generated_files/' + prompt + '-' + gpt_model + '.py'\n",
    "        output_file = './generated_files/{}/{}/{}-{}.py'.format(gpt_model, cwe, prompt, gpt_model)\n",
    "\n",
    "        # Send a prompt\n",
    "        completion = client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        store=True,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Return only code and nothing else.\"},\n",
    "            {\"role\": \"user\", \"content\": generation_prompt}\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        # Capture the response\n",
    "        response = completion.choices[0].message.content\n",
    "\n",
    "        # Write the result out to the file\n",
    "        with open(output_file, 'w+') as output_fh:\n",
    "            if response.startswith('```'):\n",
    "                response = '\\n'.join(response.split('\\n')[1:-1])\n",
    "\n",
    "            output_fh.write(response)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Analysis\n",
    "Code analysis results from CodeQL and SonarCloud have been orchestrated using GitHub Actions.\n",
    "\n",
    "- CodeQL Results: https://github.com/lylebarner/COMSCI263-final-project/security/code-scanning\n",
    "- SonarCloud Results: https://sonarcloud.io/summary/overall?id=lylebarner_COMSCI263-final-project&branch=main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
